{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch1. 绪论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.1 两种正则化技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 岭回归 ridge regression\n",
    "- 套索\n",
    "\n",
    "在回归问题中，通常模型复杂度几何，与数据的复杂度有关，一般来说，数据量较少的情况下，模型不能太复杂，需要加入一定的正则化项，以约束模型参数。\n",
    "\n",
    "1. 岭回归\n",
    "$$\\mathcal Loss = \\hat{\\textbf{E}}(\\textbf{w}) = \\frac{1}{2}\\sum_{n=1}^{N}\\{\\hat{y}(x_n, \\textbf{w}) - y_n\\}^2 + \\frac{\\lambda}{2}\\|w\\|_{2}^{2}$$\n",
    "\n",
    "2. 套索lasso\n",
    "$$\\mathcal Loss = \\hat{\\textbf{E}}(\\textbf{w}) = \\frac{1}{2}\\sum_{n=1}^{N}\\{\\hat{y}(x_n, \\textbf{w}) - y_n\\}^2 + \\frac{\\lambda}{2}\\|w\\|_{1}$$\n",
    "\n",
    "岭回归对各个元素平方和再求平方根，即L2范数约束，从而使得各个元素都接近于0，与L1范数不同，L2范数规划后w的值会接近于0但不到0，而L1范数规范后可能令w的一些值为0，所以L1范数规范在特征选择中经常用到，而L2范数在参数规则化时经常用到。在回归模型中，L1范数，L2范数正则化，也就得到了lasso回归和岭回归。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 贝叶斯与最大似然"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**贝叶斯后验概率公式**：\n",
    "                            $$p(w|\\mathcal D) = \\frac{p(\\mathcal D|w)p(w)}{p(\\mathcal D)}$$\n",
    "其中D为观测结果，p(w)为先验概率，一般p(D)都是表示为各类的概率和：\n",
    "                            $$p(\\mathcal D) = \\sum_{c=0}^{C-1} {p(\\mathcal D|w_c)p(w_c)}$$\n",
    "或连续表达，使用积分形式。\n",
    "\n",
    "书本将计算p(D)用后验概率分布和似然函数积分得到：\n",
    "                            $$p(\\mathcal D) = \\int p(\\mathcal D|w)p(w)dw$$\n",
    "事实上，一般对观测与分布都有一个先验知识，即预先知道各个类别的概率，以及各个类别内各观测值的概率，从而可以以观测值来推导基于观测值的类后验概率。\n",
    "\n",
    "\n",
    "在贝叶斯观点和频率学家观点中,似然函数 p(D|w)都起着重要的作用。然而,在两种观点中,使用的方式有着本质的不同。在频率学家的观点中,w被认为是一个固定的参数,它的值由某种形式的“估计”来确定,这个估计的误差通过考察可能的数据集  D 的概率分布来得到。相反,从贝叶斯的观点来看,只有一个数据集 D (即实际观测到的数据集),参数的不确定性通\n",
    "过 w 的概率分布来表达。\n",
    "\n",
    "频率学家广泛使用的一个估计是最大似然(maximum likelihood)估计,其中 w 的值是使似然函数 p(D|w) 达到最大值的 w 值。这对应于选择使观察到的数据集出现概率最大的 w 的值。在机器学习的文献中,似然函数的负对数被叫做误差函数(error function)。由于负对数是单调递减的函数,最大化似然函数等价于最小化误差函数。一种决定频率学家的误差的方法是**自助法(bootstrap)**(Efron, 1979; Hastie et al., 2001)。这种方法中,多个数据集使用下面的方式创造。假设我们的原始数据集由N个数据点X = {x1,...,xN} 组成。我们可以通过随机从 X 中抽取 N 个点的方式,创造一个新的数据集 XB 。抽取时可以有重复,因此某些 X 中的数据点可能在 XB 中有重复,而其他的在 X 中的点会在 XB 中缺失。这个过程可以重复 L 次,生成 L 个数据集,每个数据集的大小都是 N ,每个数据集是通过对原始数据集 X 采样得到的。参数估计的统计准确性之后就可以通过考察不同的自助数据集之间的预测的变化性来进行评估。\n",
    "\n",
    "贝叶斯观点的一个优点是对先验概率的包含是很自然的事情。例如,假定投掷一枚普通的硬币3次,每次都是正面朝上。一个经典的最大似然模型在估计硬币正面朝上的概率时,结果会是1,表示所有未来的投掷都会是正面朝上!相反,一个带有任意的合理的先验的贝叶斯的方法将不会得出这么极端的结论。\n",
    "\n",
    "关于频率学家的观点和贝叶斯的观点的相对优势有很多争论。事实上并没有纯粹的频率学家观点或者贝叶斯的观点。例如,针对贝叶斯方法的一种广泛的批评就是先验概率的选择通常是为了计算的方便而不是为了反映出任何先验的知识。某些人甚至把贝叶斯观点中结论对于先验选择的依赖性的本质看成困难的来源。减少对于先验的依赖性是所谓无信息(noninformative)先验的一个研究动机。然而,这会导致比较不同模型时的困难,并且实际上当先验选择不好的时候,贝叶斯方法有很大的可能性会给出错误的结果。频率学家估计方法在一定程度上避免了这一问题,并且例如交叉验证的技术在模型比较等方面也很有用。\n",
    "\n",
    "本书着重强调贝叶斯观点,这反映出过去几年贝叶斯方法在实际应用中重要性的逐渐增长。本书也会在必要的时候讨论有用的频率学家观点下的概念。虽然贝叶斯的框架起源于18世纪,但是贝叶斯方法的实际应用在很长时间内都被执行完整的贝叶斯步骤的困难性所限制,尤其是需要在整个参数空间求和或者求积分,这在做预测或者比较不同的模型时必须进行。取样方法的发展,例如马尔科夫链蒙特卡罗(在第11章讨论),以及计算机速度和存储容量的巨大提升,打开了在相当多的问题中使用贝叶斯技术的大门。蒙特卡罗方法非常灵活,可以应用于许多种类的模型。然而,它们在计算上很复杂,主要应用于小规模问题。\n",
    "\n",
    "最近,许多高效的判别式方法被提出来,例如变种贝叶斯( variational Bayes )和期望传播(expectation propagation)。这些提供了一种可选的补充的取样方法,让贝叶斯方法能够应用于大规模的应用中(Blei et al., 2003)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 高斯分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本小部分内容意欲介绍高斯分布的类型，一元或多元高斯分布，之后介绍简单性质"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一元高斯分布\n",
    "     $$\\mathcal N(x|\\mu, \\sigma ^2) = \\frac{1}{(2\\pi\\sigma^2)^{1/2}}\\exp \\{-\\frac{1}{2\\sigma^2}(x-\\mu )^2\\}$$\n",
    "  基本性质：$\\mathbb E[x]=\\mu, \\mathit{var}[x]=\\mathbb E[x^2]- \\mathbb E[x]^2 = \\sigma^2$\n",
    "\n",
    "- D维高斯分布\n",
    "     $$\\mathcal N (\\textbf{x}|\\mu, \\sum) = \\frac{1}{(2\\pi)^{\\mathcal D}/2 |\\sum|^{1/2}} \\exp \\{-\\frac{1}{2}(\\textbf{x}-\\mu)^{T}\\sum{}{}^{-1}(\\textbf{x}-\\mu\\}$$\n",
    "     \n",
    "  $\\sum $为协方差矩阵，维度为DxD，||表示行列式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
